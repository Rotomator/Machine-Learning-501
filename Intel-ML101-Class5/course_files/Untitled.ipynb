{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-afde3cba2440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoeff_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcoeff_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_l1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_l2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoeff_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoeff_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine all the coefficients into a dataframe \n",
    "coefficients = list() \n",
    " \n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab, mod in zip(coeff_labels, coeff_models): \n",
    "    coeffs = mod.coef_\n",
    "    coeff_label = pd.MultiIndex(levels = [[lab], [0,1,2,3,4,5]], \n",
    "                                labels = [[0,0,0,0,0,0], [0,1,2,3,4,5]])\n",
    "    coefficients.append(pd.DataFrame(coeffs.T, columns = coeff_label))\n",
    "    # .T transposes index and columns \n",
    "    # coefficients is a list of 3 (lr, lr_l1, lr_l2) matrices (561x6)\n",
    "\n",
    "# concatenate matrices by column     \n",
    "coefficients = pd.concat(coefficients, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot 6 plots of each multi-class coefficient \n",
    "fig, axList = plt.subplots(nrows = 3, ncols = 2)\n",
    "axList = axList.flatten()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "# iterate through each classification 0,1,2,3,4,5\n",
    "for ax in enumerate(axList): \n",
    "    loc = ax[0] # loc is 0,1,2,3,4,5 for each plot/classification\n",
    "    ax = ax[1]\n",
    "    # print(loc, ax)\n",
    "    \n",
    "    # .xs() returns column (axis = 1) of coefficients for each class (loc)\n",
    "    data = coefficients.xs(loc, level = 1, axis = 1) # level 1 is labels (lr,..)\n",
    "    # print (data.head(10)) # data is all the coefficients for each class\n",
    "    data.plot(marker = 'o', ls = '', ms = 2.0, ax = ax, legend = False)\n",
    "    \n",
    "    if ax is axList[0]: # if 1st plot, plot legend\n",
    "        ax.legend(loc = 4) # location of legend (loc=4 is 'lower right')\n",
    "    \n",
    "    ax.set(title = 'Coefficient Set' + str(loc))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the class and the probability for each \n",
    "\n",
    "y_pred = list()\n",
    "y_prob = list() \n",
    "\n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab, mod in zip(coeff_labels, coeff_models): \n",
    "    y_pred.append(pd.Series(mod.predict(X_test), \n",
    "                            name = lab))\n",
    "    y_prob.append(pd.Series(mod.predict_proba(X_test)\n",
    "                            .max(axis = 1),  # prob of highest class\n",
    "                            name = lab))\n",
    "    \n",
    "y_pred = pd.concat(y_pred, axis = 1)\n",
    "y_prob = pd.concat(y_prob, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "metrics = list() \n",
    "cm = dict() \n",
    "\n",
    "for lab in coeff_labels: \n",
    "    \n",
    "    # precision, recall, f-score from the multi-class support function \n",
    "    precision, recall, fscore, __ = score(y_test, y_pred[lab], \n",
    "                                          average = 'weighted')\n",
    "    \n",
    "    # usual way to calculate accuracy \n",
    "    accuracy = accuracy_score(y_test, y_pred[lab])\n",
    "    \n",
    "    # ROC-AUC scores can be calculated by binarizing the data \n",
    "    auc = roc_auc_score(label_binarize(y_test, classes = [0,1,2,3,4,5]), \n",
    "                        label_binarize(y_pred[lab], classes = [0,1,2,3,4,5]), \n",
    "                        average = 'weighted')\n",
    "    \n",
    "    # confusion matrix \n",
    "    cm[lab] = confusion_matrix(y_test, y_pred[lab])\n",
    "    \n",
    "    metrics.append(pd.Series({'precision': precision, \n",
    "                              'recall': recall, \n",
    "                              'fscore': fscore, \n",
    "                              'accuracy': accuracy, \n",
    "                              'auc': auc}, name = lab))\n",
    "    \n",
    "metrics = pd.concat(metrics, axis = 1)\n",
    "metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "fig, axList = plt.subplots(nrows = 2, ncols = 2)\n",
    "axList = axList.flatten()\n",
    "fig.set_size_inches(12, 10)\n",
    "\n",
    "axList[-1].axis('off') # takes away 4th plot \n",
    "\n",
    "for ax, lab in zip(axList[:-1], coeff_labels): \n",
    "    sns.heatmap(cm[lab], \n",
    "                ax = ax, \n",
    "                annot = True, # annotate each cell w/ number\n",
    "                fmt = 'd'); # annotate with integer format (as opposed to 5e83)\n",
    "    ax.set(title = lab); \n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:idp]",
   "language": "python",
   "name": "conda-env-idp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
